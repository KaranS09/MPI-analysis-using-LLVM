# Analyzing Uniform Participation of MPI Processes Using LLVM/Clang

This project aims to analyze the uniform participation patterns of MPI processes in C/C++ code using LLVM/Clang. By leveraging the LLVM framework, we develop a custom analysis pass that identifies MPI communication calls and detects patterns of uniform participation among MPI processes.

## Features

- **MPI Communication Analysis**: Detects and analyzes MPI_Send and MPI_Recv calls.
- **Uniform Participation Detection**: Identifies uniform participation patterns across MPI processes.
- **LLVM/Clang Integration**: Utilizes LLVM's powerful analysis and transformation capabilities.
- **Detailed Reporting**: Provides comprehensive reports on detected communication patterns.

## Explanation of Each Code File

- **[mpi_example.c](./final/mpi_example.c)**: A simple MPI program demonstrating point-to-point communication between two processes. The root process sends data to another process, which receives and prints it.

- **[MPIAnalysisPass.cpp](./final/MPIAnalysisPass.cpp)**: An LLVM pass that analyzes MPI communication patterns in the provided code. It detects MPI_Send and MPI_Recv calls, extracts relevant information, and analyzes uniform participation patterns among the MPI processes.

- **[input.ll](./final/input.ll)**: LLVM IR (Intermediate Representation) of the mpi_example.c code, generated by Clang. This file serves as the input for the LLVM pass.

## Steps to Run the Analysis

### One-Time Setup Instructions

1. **Check MPI Compiler Location:**

   ```sh
   mpicc -show
   ```

2. **Generate LLVM IR from MPI C Code:**

   ```sh
   clang -I/usr/include/lam -emit-llvm -S mpi_example.c -o input.ll
   ```

   This command generates the LLVM IR file `input.ll` from the provided MPI C code in `mpi_example.c`.

   Note: Use the `find` command to locate the MPI header files if the above command fails.

   ```sh
   find /usr -name mpi.h
   ```

   Paste the path to the MPI header files in the clang command:

   ```sh
   clang -I<mpi_header_path> -emit-llvm -S mpi_example.c -o input.ll
   ```

### Execution Instructions

1. **Compile the MPI Analysis Pass:**

   ```sh
   clang++ -shared -fPIC -o MPIAnalysisPass.so MPIAnalysisPass.cpp `llvm-config --cxxflags --ldflags --libs`
   ```

   This command compiles the MPIAnalysisPass.cpp file into a shared object file (MPIAnalysisPass.so) that can be loaded as an LLVM pass.

2. **Run the Analysis Pass:**

   ```sh
   opt -load-pass-plugin=./MPIAnalysisPass.so -passes="mpi-analysis" < input.ll > /dev/null
   ```

   This command runs the MPI analysis pass on the LLVM IR file `input.ll` and generates the analysis report. The `MPIAnalysisPass.so` shared object file is loaded as a plugin, and the `mpi-analysis` pass is executed on the input LLVM IR.

## Output Example

```text
MPIAnalysisPass running on function: main
[INFO] Detected MPI MPI_Send: comm=MPI_COMM_WORLD, tag=0, rank=1
[INFO] Detected MPI MPI_Recv: comm=MPI_COMM_WORLD, tag=0, rank=32765
[INFO] Analyzing Uniform Participation Patterns...
[INFO] Uniform Participation Detected in Comm MPI_COMM_WORLD with Tag 0 involving Ranks: 1 32765
Uniform Participation Report:
------------------------------------
- Communicator: MPI_COMM_WORLD
- Tag: 0
- Participating Ranks: {1, 32765}
This indicates that both MPI_Send and MPI_Recv operations with tag 0 in communicator
MPI_COMM_WORLD involve these ranks.
```

## comm, tag, rank

In MPI (Message Passing Interface), `comm`, `tag`, and `rank` are key concepts used to manage and control the communication between processes in a parallel application. Here's a description of each:

### 1. `comm` (Communicator)

- **Definition**: A communicator in MPI is an object that defines a group of processes that can communicate with each other. It essentially encapsulates the communication context.
- **Common Communicators**:

  - `MPI_COMM_WORLD`: The default communicator that includes all the processes in the MPI program.
  - User-defined communicators: You can create custom communicators to group specific processes for more specialized communication.

- **Usage**: Communicators are passed as arguments to most MPI functions to specify the group of processes involved in the communication.
- **Example**:

  ```c
  MPI_Comm comm = MPI_COMM_WORLD;
  MPI_Send(buffer, count, datatype, dest, tag, comm);
  ```

### 2. `tag`

- **Definition**: A tag is an integer identifier used to distinguish between different messages. It allows processes to filter incoming messages based on their tag value.
- **Usage**: Tags are used in both sending and receiving messages. The sender assigns a tag to a message, and the receiver can specify which tag to receive.
- **Example**:

  ```c
  int tag = 99;
  MPI_Send(buffer, count, datatype, dest, tag, comm);
  MPI_Recv(buffer, count, datatype, source, tag, comm, &status);
  ```

### 3. `rank`

- **Definition**: A rank is a unique identifier assigned to each process within a communicator. It is used to specify the source or destination of a message.
- **Usage**: The rank of a process is used to identify it among the group of processes in a communicator. Each process can query its own rank using `MPI_Comm_rank`.
- **Example**:

  ```c
  int rank;
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  if (rank == 0) {
      // Code for process with rank 0
  } else {
      // Code for other processes
  }
  ```

### Summary in Context

When sending a message from one process to another using MPI, you specify the communicator (`comm`), the rank of the destination process, and a tag to identify the message. For example, the `MPI_Send` function would send data from the calling process to another process identified by its rank within the given communicator, using a specified tag. The receiving process would use `MPI_Recv` with the same communicator and tag to correctly receive and identify the message.

## Prerequisites

- **LLVM/Clang:** Ensure you have LLVM and Clang installed.
- **MPI Library:** Ensure you have an MPI library installed, such as OpenMPI or MPICH.
